import pandas as pd
import numpy as np


columnsDefined = ['symboling', 'normalized-losses', 'make', 'fuel-type', 'aspiration', 'num-of-doors', 'body-style', 'drive-wheels', 'engine-location', 'wheel-base', 'length', 'width', 'height', 'curb-weight', 'engine-type', 'num-of-cylinders', 'engine-size', 'fuel-system', 'bore', 'stroke', 'compression-ratio', 'horsepower', 'peak-rpm' ,'city-mpg', 'highway-mpg', 'price']
cars = pd.read_csv(r'imports-85.data', names=columnsDefined)


numCars=cars.drop(['symboling', 'make', 'fuel-type', 'aspiration', 'num-of-doors', 'body-style', 'drive-wheels', 'engine-location' ,'engine-type', 'num-of-cylinders', 'fuel-system'], axis=1)
numCars.head()

numCars = numCars.replace('?', np.nan)
numCars.head()

numCars = numCars.astype('float')
numCars.dtypes

numCars = numCars.drop(['normalized-losses', 'bore', 'stroke', 'horsepower', 'peak-rpm'], axis=1)

numCars = numCars.dropna(subset=['price'])
#numCars.head()
numCars.isnull().sum()

from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error

def knn_train_test(trainColumn, targetColumn, df):
    np.random.seed(1)
    randomizedSet = np.random.permutation(df.index)
    shuffledSet = df.reindex(randomizedSet)
    halvesSet = int(len(randomizedSet) / 2)
    trainData = shuffledSet.iloc[0:halvesSet]
    testData = shuffledSet.iloc[halvesSet:]
    
    k_parameters = [1, 3, 5, 7, 9]
    rmse_k = {}
    for k in k_parameters:
        knn = KNeighborsRegressor(n_neighbors=k)
        knn.fit(trainData[[trainColumn]], trainData[targetColumn])
        predictions = knn.predict(testData[[trainColumn]])
        rmse = mean_squared_error(testData[targetColumn], predictions)**(1/2)
        rmse_k[k] = rmse

    return rmse_k

rmseResultsUni = {}
#go through each column in df except target
modelColumns = numCars.columns.drop('price')

for col in modelColumns:
    rmseValues = knn_train_test(col,'price',numCars)
    rmseResultsUni[col] = rmseValues

rmseResultsUni

from matplotlib import pyplot as plt

%matplotlib inline

"""
x= [0, 1, 2, 3, 4, 5, 6, 7, 8]
values=['City MPG', 'Compression Ratio', 'Curb Weight', 'Engine Size', 'Height', 'Highway MPG', 'Length', 'Wheel Base', 'Width']
df = pd.DataFrame(rmseResultsUni)
df2 = df.transpose()
df2.plot(figsize=(8,6)
plt.xlabel('Attributes')
plt.ylabel('RMSE Value')
plt.xticks(x,values,rotation=90)
plt.title=('Univariate Error Values')
plt.legend()
plt.show()
"""
x= [0, 1, 2, 3, 4, 5, 6, 7, 8]
values=['City MPG', 'Compression Ratio', 'Curb Weight', 'Engine Size', 'Height', 'Highway MPG', 'Length', 'Wheel Base', 'Width']
df = pd.DataFrame(rmseResultsUni)
df2 = df.transpose()
df2.plot(figsize=(8,6), kind='bar')
plt.xlabel('Attribute')
plt.ylabel('RMSE Value')
plt.xticks(x,values,rotation=90)
plt.legend()
plt.show()

from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error

def knn_train_test(trainColumn, targetColumn, df):
    np.random.seed(1)
    randomizedSet = np.random.permutation(df.index)
    shuffledSet = df.reindex(randomizedSet)
    halvesSet = int(len(randomizedSet) / 2)
    trainData = shuffledSet.iloc[0:halvesSet]
    testData = shuffledSet.iloc[halvesSet:]
    
    k_parameters = [5]
    rmse_k = {}
    for k in k_parameters:
        knn = KNeighborsRegressor(n_neighbors=k)
        knn.fit(trainData[[trainColumn]], trainData[targetColumn])
        predictions = knn.predict(testData[[trainColumn]])
        rmse = mean_squared_error(testData[targetColumn], predictions)**(1/2)
        rmse_k[k] = rmse

    return rmse_k

rmseResultsUni = {} #dict for results
#go through each column in df except target
train_cols = numCars.columns.drop('price')

for col in train_cols:
    rmseValues = knn_train_test(col,'price', numCars)
    rmseResultsUni[col] = rmseValues


colFeats = {} #average rmse of reiterated k-values for each attribute, or feature
for k, v in rmseResultsUni.items():
    avgRmse = np.mean(list(v.values()))
    colFeats[k] = avgRmse

col_feats_avg = pd.Series(colFeats)
colSorted = col_feats_avg.sort_values() #sorted values reflects 'best' features by having lowest errors ascending
print(colSorted)
sorted_index = colSorted.index
print(sorted_index)

def knn_train_test(trainColumn, targetColumn, df):
    np.random.seed(1)
    randomizedSet = np.random.permutation(df.index)
    shuffledSet = df.reindex(randomizedSet)
    halvesSet = int(len(randomizedSet) / 2)
    trainData = shuffledSet.iloc[0:halvesSet]
    testData = shuffledSet.iloc[halvesSet:]
    
    k_parameters = [i for i in range(1, 26)]
    rmse_k = {}
    for k in k_parameters:
        knn = KNeighborsRegressor(n_neighbors=k)
        knn.fit(trainData[[trainColumn]], trainData[targetColumn])
        predictions = knn.predict(testData[[trainColumn]])
        rmse = mean_squared_error(testData[targetColumn], predictions)**(1/2)
        rmse_k[k] = rmse

    return rmse_k


rmseResultsMulti = {}
for bestFeats in range(2, 7):
    rmseResultsMulti['{} Best Features'.format(bestFeats)] = knn_train_test(sorted_index[bestFeats], 'price', numCars)

rmseResultsMulti
